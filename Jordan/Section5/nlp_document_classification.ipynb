{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import(\n",
    "    datasets, feature_extraction, model_selection, \n",
    "    pipeline, naive_bayes, metrics\n",
    ")\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(corpus):\n",
    "    '''Extract TF-IDF features from corpus'''\n",
    "    stop_words = nltk.corpus.stopwords.words('english')\n",
    "    count_vectorizer = feature_extraction.text.CountVectorizer(\n",
    "        tokenizer=nltk.word_tokenize,\n",
    "        stop_words=stop_words,\n",
    "        min_df=2, # The word must appear more than once\n",
    "        # The higher ngram range is, the higher the vector space and computing cost\n",
    "        ngram_range=(1, 2), # Allows for 1 and 2 word combinations\n",
    "    )\n",
    "    processed_corpus = count_vectorizer.fit_transform(corpus)\n",
    "    # Can change params of TfidfTransformer if it lowers performance\n",
    "    processed_corpus = feature_extraction.text.TfidfTransformer(\n",
    "        ).fit_transform(processed_corpus)\n",
    "    \n",
    "    return processed_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19997 files loaded.\n",
      "They contain the following classes: ['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n",
      "\n",
      "Newsgroups: rec.sport.hockey\n",
      "Path: cantaloupe.srv.cs.cmu.edu!crabapple.srv.cs.cmu.edu!fs7.ece.cmu.edu!europa.eng.gtefsd.com!howland.reston.ans.net!zaphod.mps.ohio-state.edu!uwm.edu!cs.utexas.edu!utnut!alchemy.chem.utoronto.ca!golchowy\n",
      "From: golchowy@alchemy.chem.utoronto.ca (Gerald Olchowy)\n",
      "Subject: Re: RUMOUR - Keenan signs with Rangers?\n",
      "Message-ID: <1993Apr16.222232.17393@alchemy.chem.utoronto.ca>\n",
      "Organization: University of Toronto Chemistry Department\n",
      "References: <1993Apr16.171347.784@news.columbia.edu> <1993Apr16.183110.838@alchemy.chem.utoronto.ca> <1993Apr16.185823.6310@news.columbia.edu>\n",
      "Date: Fri, 16 Apr 1993 22:22:32 GMT\n",
      "Lines: 25\n",
      "\n",
      "In article <1993Apr16.185823.6310@news.columbia.edu> gld@cunixb.cc.columbia.edu (Gary L Dare) writes:\n",
      ">\n",
      ">Interestingly, Keenan's co-coach (or is it his \"Number One\"?) on Team\n",
      ">Canada at the World Championships is Roger Neilsen.  \n",
      ">\n",
      "\n",
      "But ultimately their hockey philosophies are like night and day...\n",
      "Keenan believes in pressuring the opposition and taking the\n",
      "initiative (within the limits of his system)...while Roger\n",
      "has a reactive hockey philosophy...which is why Messier will\n",
      "be able to and has played for Keenan, but thought Roger's way\n",
      "was a sure loser.\n",
      "\n",
      ">It'd be interesting if the Rangers call in the balance of Neilsen's\n",
      ">contract to be Keenan's assistant ...  Roger did do a very good job\n",
      ">with the mediocre players, just as he handled the Cinderella Canucks\n",
      ">of 10 years ago ... but his mistake was playing the Rangers like those\n",
      ">Canucks last May ...\n",
      ">\n",
      "\n",
      "Roger is a great assistant coach...but considering what must be bad\n",
      "blood between Nielson and Messier, it would be a mistake to bring\n",
      "him back even in that role.\n",
      "\n",
      "Gerald\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_filepath = '20_news_groups/20_newsgroups'\n",
    "\n",
    "newsgroups_data = datasets.load_files(\n",
    "    data_filepath, shuffle=True, random_state=42, encoding='ISO-8859-1')\n",
    "print(f'{len(newsgroups_data.data)} files loaded.')\n",
    "print(f'They contain the following classes: {newsgroups_data.target_names}')\n",
    "print()\n",
    "print(newsgroups_data.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_validate_train_split(X, y,\n",
    "                              test_size: float = None,\n",
    "                              random_state: int = None, **kwargs\n",
    "                              ) -> tuple:\n",
    "    '''\n",
    "        Completes Sci-Kit Learn's test_train_split twice to split data into\n",
    "        three sections\n",
    "        \n",
    "        Paramaters:\n",
    "        X: The dataset without the target present\n",
    "        y: The target values of the dataset\n",
    "        test_size: The proportion of the data set in the test set.\n",
    "            It is also the proportion of the remainder used for the validation set\n",
    "        random_state: Controls the shuffling \n",
    "        **kwargs: These are passed to both test_train_split functions\n",
    "        \n",
    "        Returns a tuple of:\n",
    "            X_train, X_validate, X_test, y_train, y_validate, y_test\n",
    "    '''\n",
    "    # Complete test_train split\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state, **kwargs)\n",
    "\n",
    "    # Complete the test_validation split\n",
    "    X_train, X_validate, y_train, y_validate = train_test_split(\n",
    "        X_train_val, y_train_val, test_size=test_size,\n",
    "        random_state=random_state, **kwargs)\n",
    "    \n",
    "    return X_train, X_validate, X_test, y_train, y_validate, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete a test_validate_train split\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = test_validate_train_split(\n",
    "    newsgroups_data.data, newsgroups_data.target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the stop words\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "# Given out tokenizer there is an issue with contracted words from our stop_words\n",
    "# you'd is in out stop_words, but is tokenised to [\"you\", \"'d\"]\n",
    "# which would be missed, so run our stop words through the tokenizer to match\n",
    "nested_tokenized_stop_words = [nltk.word_tokenize(stop_word) for stop_word in stop_words]\n",
    "# This results in a list of lists which need to be flattened\n",
    "tokenized_stop_words = [word\n",
    "                        # for each list in the bigger list we want\n",
    "                        for list_of_words in nested_tokenized_stop_words\n",
    "                        # each word in the list\n",
    "                        for word in list_of_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model pipeline\n",
    "# Pipeline accepts a list of tuples, a name of a step, and a step\n",
    "model = Pipeline([\n",
    "    ('counts', feature_extraction.text.CountVectorizer(\n",
    "        tokenizer=nltk.word_tokenize,\n",
    "        min_df=2,\n",
    "        ngram_range=(1,2),\n",
    "        stop_words=tokenized_stop_words,\n",
    "    )),\n",
    "    ('tfidf', feature_extraction.text.TfidfTransformer()),\n",
    "    ('naivebayes', naive_bayes.MultinomialNB()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jsshe\\Documents\\learning\\oreilly\\Hands-on-NLP-with-NLTK-and-scikit-learn\\.venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of multinomial naive bayes = 0.8865625\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_val)\n",
    "print(f'Accuracy of multinomial naive bayes = {np.mean(y_pred==y_val)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
